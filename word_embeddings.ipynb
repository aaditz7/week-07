{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: absl-py==2.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: appnope==0.1.4 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.1.4)\n",
      "Requirement already satisfied: asttokens==2.4.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.4.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.6.3)\n",
      "Requirement already satisfied: certifi==2024.8.30 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer==3.4.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (3.4.0)\n",
      "Requirement already satisfied: comm==0.2.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (0.2.2)\n",
      "Requirement already satisfied: contourpy==1.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: cycler==0.12.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (0.12.1)\n",
      "Requirement already satisfied: debugpy==1.8.7 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (1.8.7)\n",
      "Requirement already satisfied: decorator==5.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (5.1.1)\n",
      "Requirement already satisfied: executing==2.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (2.1.0)\n",
      "Requirement already satisfied: flatbuffers==24.3.25 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (24.3.25)\n",
      "Requirement already satisfied: fonttools==4.54.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 14)) (4.54.1)\n",
      "Requirement already satisfied: gast==0.6.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (0.2.0)\n",
      "Requirement already satisfied: grpcio==1.67.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 17)) (1.67.1)\n",
      "Requirement already satisfied: h5py==3.12.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (3.12.1)\n",
      "Requirement already satisfied: idna==3.10 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 19)) (3.10)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 20)) (6.29.5)\n",
      "Requirement already satisfied: ipython==8.29.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 21)) (8.29.0)\n",
      "Requirement already satisfied: jedi==0.19.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 22)) (0.19.1)\n",
      "Requirement already satisfied: joblib==1.4.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 23)) (1.4.2)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 24)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 25)) (5.7.2)\n",
      "Requirement already satisfied: keras==3.6.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 26)) (3.6.0)\n",
      "Requirement already satisfied: kiwisolver==1.4.7 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 27)) (1.4.7)\n",
      "Requirement already satisfied: libclang==18.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 28)) (18.1.1)\n",
      "Requirement already satisfied: lxml==5.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 29)) (5.3.0)\n",
      "Requirement already satisfied: Markdown==3.7 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 30)) (3.7)\n",
      "Requirement already satisfied: markdown-it-py==3.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 31)) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 32)) (3.0.2)\n",
      "Requirement already satisfied: matplotlib==3.9.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 33)) (3.9.2)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 34)) (0.1.7)\n",
      "Requirement already satisfied: mdurl==0.1.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 35)) (0.1.2)\n",
      "Requirement already satisfied: ml-dtypes==0.4.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 36)) (0.4.1)\n",
      "Requirement already satisfied: namex==0.0.8 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 37)) (0.0.8)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 38)) (1.6.0)\n",
      "Requirement already satisfied: numpy==2.0.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 39)) (2.0.2)\n",
      "Requirement already satisfied: opt_einsum==3.4.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 40)) (3.4.0)\n",
      "Requirement already satisfied: optree==0.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 41)) (0.13.0)\n",
      "Requirement already satisfied: packaging==24.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 42)) (24.1)\n",
      "Requirement already satisfied: pandas==2.2.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 43)) (2.2.3)\n",
      "Requirement already satisfied: parso==0.8.4 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 44)) (0.8.4)\n",
      "Requirement already satisfied: pexpect==4.9.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 45)) (4.9.0)\n",
      "Requirement already satisfied: pillow==11.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 46)) (11.0.0)\n",
      "Requirement already satisfied: platformdirs==4.3.6 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 47)) (4.3.6)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.48 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 48)) (3.0.48)\n",
      "Requirement already satisfied: protobuf==5.28.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 49)) (5.28.3)\n",
      "Requirement already satisfied: psutil==6.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 50)) (6.1.0)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 51)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 52)) (0.2.3)\n",
      "Requirement already satisfied: Pygments==2.18.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 53)) (2.18.0)\n",
      "Requirement already satisfied: pyparsing==3.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 54)) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 55)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz==2024.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 56)) (2024.2)\n",
      "Requirement already satisfied: pyzmq==26.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 57)) (26.2.0)\n",
      "Requirement already satisfied: requests==2.32.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 58)) (2.32.3)\n",
      "Requirement already satisfied: rich==13.9.4 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 59)) (13.9.4)\n",
      "Requirement already satisfied: scikit-learn==1.5.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 60)) (1.5.2)\n",
      "Requirement already satisfied: scipy==1.14.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 61)) (1.14.1)\n",
      "Requirement already satisfied: setuptools==75.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 62)) (75.3.0)\n",
      "Requirement already satisfied: six==1.16.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 63)) (1.16.0)\n",
      "Requirement already satisfied: stack-data==0.6.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 64)) (0.6.3)\n",
      "Requirement already satisfied: tensorboard==2.18.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 65)) (2.18.0)\n",
      "Requirement already satisfied: tensorboard-data-server==0.7.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 66)) (0.7.2)\n",
      "Requirement already satisfied: tensorflow==2.18.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 67)) (2.18.0)\n",
      "Requirement already satisfied: termcolor==2.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 68)) (2.5.0)\n",
      "Requirement already satisfied: threadpoolctl==3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 69)) (3.5.0)\n",
      "Requirement already satisfied: tornado==6.4.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 70)) (6.4.1)\n",
      "Requirement already satisfied: traitlets==5.14.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 71)) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 72)) (4.12.2)\n",
      "Requirement already satisfied: tzdata==2024.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 73)) (2024.2)\n",
      "Requirement already satisfied: urllib3==2.2.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 74)) (2.2.3)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 75)) (0.2.13)\n",
      "Requirement already satisfied: Werkzeug==3.1.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 76)) (3.1.2)\n",
      "Requirement already satisfied: wheel==0.44.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 77)) (0.44.0)\n",
      "Requirement already satisfied: wrapt==1.16.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 78)) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (75.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install setuptools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson derived from https://www.tensorflow.org/text/guide/word_embeddings\n",
    "\n",
    "# Word Embeddings\n",
    "\n",
    "Word embeddings are ways of representing words as numerical vectors. These vectors can account for a word's context, allowing us to calculate its similarity to other words in its corpus: word's that appear in the same context might be synonyms, or they might simply be used in similar ways.\n",
    "\n",
    "Consider the examples \"run\" and \"walk\": a good word embeddings model would have these words very close in vector-space; similarly, \"mother\" and \"father\" or \"Boston\" and \"Massachusetts\".\n",
    "\n",
    "## One-hot encodings\n",
    "\n",
    "One naïve way to capture this information is to encode each word's location in a vocabulary as a 1 and every other word as a 0. This is known as **one-hot encoding**, and it typically doesn't get us very far: each word's vector has to be the length of the vocabulary, even though it is mostly filled with 0s.\n",
    "\n",
    "This is what is known as a \"sparse\" index.\n",
    "\n",
    "## Unique numbers\n",
    "\n",
    "As a second attempt, you might assign each word a unique number. But this approach, while \"denser\" than a one-hot encoding, fails to capture any contextual information about a given word.\n",
    "\n",
    "## Enter word embeddings\n",
    "\n",
    "Word embeddings are trained models that produce dense representations of words in a corpus. Smaller corpora might have 8 dimensions, while larger corpora can have up to 1024 dimensions.\n",
    "\n",
    "We're going to attempt to train an embeddings model on the Greek texts in `./data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 17:13:13.546617: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-13 17:13:19.699831: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-13 17:13:22.595172: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731518007.893889    2163 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731518008.913552    2163 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-13 17:13:38.655999: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31 files belonging to 3 classes.\n",
      "Using 25 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 17:14:06.679567: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31 files belonging to 3 classes.\n",
      "Using 6 files for validation.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "batch_size = 1024\n",
    "seed = random.randint(0, 1000)\n",
    "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    \"data\", batch_size=batch_size, validation_split=0.2, subset=\"training\", seed=seed\n",
    ")\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    \"data\", batch_size=batch_size, validation_split=0.2, subset=\"validation\", seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(1000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02184906,  0.01496544,  0.04675484, -0.02853587, -0.02673086],\n",
       "       [-0.01613537, -0.01207625, -0.03244214,  0.00352241, -0.04177449],\n",
       "       [ 0.03279482, -0.01017033,  0.00553141, -0.04403266,  0.04552792]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = embedding_layer(tf.constant([1, 2, 3]))\n",
    "result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = embedding_layer(tf.constant([[0, 1, 2], [3, 4, 5]]))\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 17:14:25.441425: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "  return tf.strings.regex_replace(stripped_html,\n",
    "                                  '[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "\n",
    "# Vocabulary size and number of words in a sequence.\n",
    "vocab_size = 10000\n",
    "sequence_length = 100\n",
    "\n",
    "# Use the text vectorization layer to normalize, split, and map strings to\n",
    "# integers. Note that the layer uses the custom standardization defined above.\n",
    "# Set maximum_sequence length as all samples are not of the same length.\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)\n",
    "\n",
    "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
    "text_ds = train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=16\n",
    "\n",
    "model = Sequential([\n",
    "  vectorize_layer,\n",
    "  Embedding(vocab_size, embedding_dim, name=\"embedding\"),\n",
    "  GlobalAveragePooling1D(),\n",
    "  Dense(16, activation='relu'),\n",
    "  Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.2400 - loss: 0.6917 - val_accuracy: 0.1667 - val_loss: 0.6865\n",
      "Epoch 2/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.2400 - loss: 0.6871 - val_accuracy: 0.1667 - val_loss: 0.6803\n",
      "Epoch 3/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.2400 - loss: 0.6820 - val_accuracy: 0.1667 - val_loss: 0.6737\n",
      "Epoch 4/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.2400 - loss: 0.6766 - val_accuracy: 0.1667 - val_loss: 0.6669\n",
      "Epoch 5/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.2400 - loss: 0.6711 - val_accuracy: 0.1667 - val_loss: 0.6599\n",
      "Epoch 6/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.2400 - loss: 0.6655 - val_accuracy: 0.1667 - val_loss: 0.6528\n",
      "Epoch 7/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.2400 - loss: 0.6597 - val_accuracy: 0.1667 - val_loss: 0.6456\n",
      "Epoch 8/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2400 - loss: 0.6539 - val_accuracy: 0.1667 - val_loss: 0.6383\n",
      "Epoch 9/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.2400 - loss: 0.6479 - val_accuracy: 0.1667 - val_loss: 0.6309\n",
      "Epoch 10/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.2400 - loss: 0.6419 - val_accuracy: 0.1667 - val_loss: 0.6234\n",
      "Epoch 11/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.2400 - loss: 0.6358 - val_accuracy: 0.1667 - val_loss: 0.6158\n",
      "Epoch 12/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.2400 - loss: 0.6296 - val_accuracy: 0.1667 - val_loss: 0.6080\n",
      "Epoch 13/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.2400 - loss: 0.6232 - val_accuracy: 0.1667 - val_loss: 0.6002\n",
      "Epoch 14/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.2400 - loss: 0.6168 - val_accuracy: 0.1667 - val_loss: 0.5922\n",
      "Epoch 15/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.2400 - loss: 0.6102 - val_accuracy: 0.1667 - val_loss: 0.5841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7d8249e5f470>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_layer('embedding').get_weights()[0]\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = weights[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " np.str_('the'),\n",
       " np.str_('to'),\n",
       " np.str_('of'),\n",
       " np.str_('and'),\n",
       " np.str_('i'),\n",
       " np.str_('you'),\n",
       " np.str_('a'),\n",
       " np.str_('in'),\n",
       " np.str_('my'),\n",
       " np.str_('for'),\n",
       " np.str_('is'),\n",
       " np.str_('that'),\n",
       " np.str_('me'),\n",
       " np.str_('not'),\n",
       " np.str_('this'),\n",
       " np.str_('with'),\n",
       " np.str_('it'),\n",
       " np.str_('your'),\n",
       " np.str_('he'),\n",
       " np.str_('will'),\n",
       " np.str_('but'),\n",
       " np.str_('his'),\n",
       " np.str_('from'),\n",
       " np.str_('have'),\n",
       " np.str_('by'),\n",
       " np.str_('what'),\n",
       " np.str_('as'),\n",
       " np.str_('be'),\n",
       " np.str_('no'),\n",
       " np.str_('on'),\n",
       " np.str_('are'),\n",
       " np.str_('who'),\n",
       " np.str_('do'),\n",
       " np.str_('her'),\n",
       " np.str_('was'),\n",
       " np.str_('all'),\n",
       " np.str_('if'),\n",
       " np.str_('so'),\n",
       " np.str_('thou'),\n",
       " np.str_('him'),\n",
       " np.str_('at'),\n",
       " np.str_('now'),\n",
       " np.str_('thy'),\n",
       " np.str_('their'),\n",
       " np.str_('or'),\n",
       " np.str_('when'),\n",
       " np.str_('one'),\n",
       " np.str_('am'),\n",
       " np.str_('we'),\n",
       " np.str_('they'),\n",
       " np.str_('man'),\n",
       " np.str_('then'),\n",
       " np.str_('has'),\n",
       " np.str_('our'),\n",
       " np.str_('she'),\n",
       " np.str_('come'),\n",
       " np.str_('would'),\n",
       " np.str_('may'),\n",
       " np.str_('there'),\n",
       " np.str_('them'),\n",
       " np.str_('these'),\n",
       " np.str_('how'),\n",
       " np.str_('thee'),\n",
       " np.str_('gods'),\n",
       " np.str_('shall'),\n",
       " np.str_('see'),\n",
       " np.str_('here'),\n",
       " np.str_('father'),\n",
       " np.str_('son'),\n",
       " np.str_('house'),\n",
       " np.str_('land'),\n",
       " np.str_('which'),\n",
       " np.str_('where'),\n",
       " np.str_('ah'),\n",
       " np.str_('o'),\n",
       " np.str_('had'),\n",
       " np.str_('an'),\n",
       " np.str_('know'),\n",
       " np.str_('did'),\n",
       " np.str_('us'),\n",
       " np.str_('zeus'),\n",
       " np.str_('were'),\n",
       " np.str_('own'),\n",
       " np.str_('city'),\n",
       " np.str_('out'),\n",
       " np.str_('yet'),\n",
       " np.str_('must'),\n",
       " np.str_('mother'),\n",
       " np.str_('men'),\n",
       " np.str_('—'),\n",
       " np.str_('can'),\n",
       " np.str_('go'),\n",
       " np.str_('death'),\n",
       " np.str_('say'),\n",
       " np.str_('upon'),\n",
       " np.str_('some'),\n",
       " np.str_('life'),\n",
       " np.str_('let'),\n",
       " np.str_('well'),\n",
       " np.str_('should'),\n",
       " np.str_('tell'),\n",
       " np.str_('too'),\n",
       " np.str_('children'),\n",
       " np.str_('why'),\n",
       " np.str_('never'),\n",
       " np.str_('more'),\n",
       " np.str_('those'),\n",
       " np.str_('than'),\n",
       " np.str_('before'),\n",
       " np.str_('take'),\n",
       " np.str_('child'),\n",
       " np.str_('god'),\n",
       " np.str_('dead'),\n",
       " np.str_('good'),\n",
       " np.str_('such'),\n",
       " np.str_('against'),\n",
       " np.str_('nor'),\n",
       " np.str_('words'),\n",
       " np.str_('friends'),\n",
       " np.str_('since'),\n",
       " np.str_('whom'),\n",
       " np.str_('hand'),\n",
       " np.str_('away'),\n",
       " np.str_('though'),\n",
       " np.str_('been'),\n",
       " np.str_('yes'),\n",
       " np.str_('any'),\n",
       " np.str_('still'),\n",
       " np.str_('even'),\n",
       " np.str_('its'),\n",
       " np.str_('up'),\n",
       " np.str_('like'),\n",
       " np.str_('hear'),\n",
       " np.str_('daughter'),\n",
       " np.str_('while'),\n",
       " np.str_('home'),\n",
       " np.str_('after'),\n",
       " np.str_('way'),\n",
       " np.str_('over'),\n",
       " np.str_('give'),\n",
       " np.str_('time'),\n",
       " np.str_('old'),\n",
       " np.str_('hands'),\n",
       " np.str_('into'),\n",
       " np.str_('long'),\n",
       " np.str_('first'),\n",
       " np.str_('without'),\n",
       " np.str_('earth'),\n",
       " np.str_('speak'),\n",
       " np.str_('once'),\n",
       " np.str_('die'),\n",
       " np.str_('oh'),\n",
       " np.str_('heart'),\n",
       " np.str_('make'),\n",
       " np.str_('many'),\n",
       " np.str_('eyes'),\n",
       " np.str_('right'),\n",
       " np.str_('only'),\n",
       " np.str_('through'),\n",
       " np.str_('things'),\n",
       " np.str_('other'),\n",
       " np.str_('just'),\n",
       " np.str_('fear'),\n",
       " np.str_('blood'),\n",
       " np.str_('wife'),\n",
       " np.str_('bring'),\n",
       " np.str_('about'),\n",
       " np.str_('could'),\n",
       " np.str_('came'),\n",
       " np.str_('myself'),\n",
       " np.str_('evil'),\n",
       " np.str_('fate'),\n",
       " np.str_('might'),\n",
       " np.str_('mine'),\n",
       " np.str_('ever'),\n",
       " np.str_('woman'),\n",
       " np.str_('indeed'),\n",
       " np.str_('think'),\n",
       " np.str_('woe'),\n",
       " np.str_('most'),\n",
       " np.str_('does'),\n",
       " np.str_('find'),\n",
       " np.str_('art'),\n",
       " np.str_('great'),\n",
       " np.str_('alas'),\n",
       " np.str_('sons'),\n",
       " np.str_('again'),\n",
       " np.str_('look'),\n",
       " np.str_('husband'),\n",
       " np.str_('back'),\n",
       " np.str_('set'),\n",
       " np.str_('left'),\n",
       " np.str_('name'),\n",
       " np.str_('made'),\n",
       " np.str_('father’s'),\n",
       " np.str_('day'),\n",
       " np.str_('forth'),\n",
       " np.str_('far'),\n",
       " np.str_('hast'),\n",
       " np.str_('another'),\n",
       " np.str_('whose'),\n",
       " np.str_('because'),\n",
       " np.str_('love'),\n",
       " np.str_('lord'),\n",
       " np.str_('down'),\n",
       " np.str_('leave'),\n",
       " np.str_('brought'),\n",
       " np.str_('both'),\n",
       " np.str_('king'),\n",
       " np.str_('bear'),\n",
       " np.str_('poor'),\n",
       " np.str_('lady'),\n",
       " np.str_('turn'),\n",
       " np.str_('same'),\n",
       " np.str_('much'),\n",
       " np.str_('marriage'),\n",
       " np.str_('women'),\n",
       " np.str_('friend'),\n",
       " np.str_('deed'),\n",
       " np.str_('heard'),\n",
       " np.str_('said'),\n",
       " np.str_('hold'),\n",
       " np.str_('unhappy'),\n",
       " np.str_('nothing'),\n",
       " np.str_('help'),\n",
       " np.str_('hath'),\n",
       " np.str_('among'),\n",
       " np.str_('wish'),\n",
       " np.str_('goddess'),\n",
       " np.str_('two'),\n",
       " np.str_('light'),\n",
       " np.str_('gone'),\n",
       " np.str_('keep'),\n",
       " np.str_('alone'),\n",
       " np.str_('sorrow'),\n",
       " np.str_('tears'),\n",
       " np.str_('fortune'),\n",
       " np.str_('sea'),\n",
       " np.str_('arms'),\n",
       " np.str_('save'),\n",
       " np.str_('power'),\n",
       " np.str_('himself'),\n",
       " np.str_('troubles'),\n",
       " np.str_('sword'),\n",
       " np.str_('escape'),\n",
       " np.str_('’tis'),\n",
       " np.str_('share'),\n",
       " np.str_('last'),\n",
       " np.str_('within'),\n",
       " np.str_('mortals'),\n",
       " np.str_('found'),\n",
       " np.str_('off'),\n",
       " np.str_('noble'),\n",
       " np.str_('learn'),\n",
       " np.str_('joy'),\n",
       " np.str_('dear'),\n",
       " np.str_('cannot'),\n",
       " np.str_('being'),\n",
       " np.str_('live'),\n",
       " np.str_('ye'),\n",
       " np.str_('race'),\n",
       " np.str_('put'),\n",
       " np.str_('head'),\n",
       " np.str_('end'),\n",
       " np.str_('done'),\n",
       " np.str_('ship'),\n",
       " np.str_('brother'),\n",
       " np.str_('mind'),\n",
       " np.str_('full'),\n",
       " np.str_('call'),\n",
       " np.str_('cause'),\n",
       " np.str_('sight'),\n",
       " np.str_('place'),\n",
       " np.str_('thus'),\n",
       " np.str_('every'),\n",
       " np.str_('very'),\n",
       " np.str_('cast'),\n",
       " np.str_('army'),\n",
       " np.str_('true'),\n",
       " np.str_('slay'),\n",
       " np.str_('others'),\n",
       " np.str_('stand'),\n",
       " np.str_('soon'),\n",
       " np.str_('wretched'),\n",
       " np.str_('rest'),\n",
       " np.str_('yourself'),\n",
       " np.str_('pity'),\n",
       " np.str_('misery'),\n",
       " np.str_('longer'),\n",
       " np.str_('grief'),\n",
       " np.str_('word'),\n",
       " np.str_('thing'),\n",
       " np.str_('gave'),\n",
       " np.str_('face'),\n",
       " np.str_('also'),\n",
       " np.str_('trouble'),\n",
       " np.str_('near'),\n",
       " np.str_('mortal'),\n",
       " np.str_('wilt'),\n",
       " np.str_('each'),\n",
       " np.str_('slain'),\n",
       " np.str_('better'),\n",
       " np.str_('best'),\n",
       " np.str_('present'),\n",
       " np.str_('phoebus'),\n",
       " np.str_('mother’s'),\n",
       " np.str_('having'),\n",
       " np.str_('beneath'),\n",
       " np.str_('kill'),\n",
       " np.str_('comes'),\n",
       " np.str_('young'),\n",
       " np.str_('tomb'),\n",
       " np.str_('murder'),\n",
       " np.str_('dost'),\n",
       " np.str_('born'),\n",
       " np.str_('body'),\n",
       " np.str_('news'),\n",
       " np.str_('heaven'),\n",
       " np.str_('ruin'),\n",
       " np.str_('night'),\n",
       " np.str_('thought'),\n",
       " np.str_('show'),\n",
       " np.str_('new'),\n",
       " np.str_('honor'),\n",
       " np.str_('country'),\n",
       " np.str_('case'),\n",
       " np.str_('side'),\n",
       " np.str_('seems'),\n",
       " np.str_('free'),\n",
       " np.str_('fire'),\n",
       " np.str_('fall'),\n",
       " np.str_('stranger'),\n",
       " np.str_('saw'),\n",
       " np.str_('ground'),\n",
       " np.str_('return'),\n",
       " np.str_('hope'),\n",
       " np.str_('sorrows'),\n",
       " np.str_('part'),\n",
       " np.str_('justice'),\n",
       " np.str_('ask'),\n",
       " np.str_('wise'),\n",
       " np.str_('sure'),\n",
       " np.str_('else'),\n",
       " np.str_('coming'),\n",
       " np.str_('sent'),\n",
       " np.str_('force'),\n",
       " np.str_('sacrifice'),\n",
       " np.str_('didst'),\n",
       " np.str_('birth'),\n",
       " np.str_('soul'),\n",
       " np.str_('shame'),\n",
       " np.str_('holy'),\n",
       " np.str_('truth'),\n",
       " np.str_('called'),\n",
       " np.str_('whether'),\n",
       " np.str_('mean'),\n",
       " np.str_('fair'),\n",
       " np.str_('enough'),\n",
       " np.str_('behold'),\n",
       " np.str_('under'),\n",
       " np.str_('speech'),\n",
       " np.str_('lead'),\n",
       " np.str_('altar'),\n",
       " np.str_('master'),\n",
       " np.str_('man’s'),\n",
       " np.str_('hard'),\n",
       " np.str_('aged'),\n",
       " np.str_('bitter'),\n",
       " np.str_('always'),\n",
       " np.str_('send'),\n",
       " np.str_('need'),\n",
       " np.str_('want'),\n",
       " np.str_('surely'),\n",
       " np.str_('sister'),\n",
       " np.str_('seen'),\n",
       " np.str_('people'),\n",
       " np.str_('o’er'),\n",
       " np.str_('bringing'),\n",
       " np.str_('happy'),\n",
       " np.str_('battle'),\n",
       " np.str_('already'),\n",
       " np.str_('whole'),\n",
       " np.str_('mistress'),\n",
       " np.str_('deeds'),\n",
       " np.str_('win'),\n",
       " np.str_('voice'),\n",
       " np.str_('thine'),\n",
       " np.str_('suffering'),\n",
       " np.str_('reason'),\n",
       " np.str_('course'),\n",
       " np.str_('cry'),\n",
       " np.str_('beyond'),\n",
       " np.str_('tale'),\n",
       " np.str_('pain'),\n",
       " np.str_('means'),\n",
       " np.str_('lot'),\n",
       " np.str_('lost'),\n",
       " np.str_('care'),\n",
       " np.str_('yours'),\n",
       " np.str_('least'),\n",
       " np.str_('killed'),\n",
       " np.str_('hair'),\n",
       " np.str_('either'),\n",
       " np.str_('alive'),\n",
       " np.str_('suffer'),\n",
       " np.str_('slave'),\n",
       " np.str_('halls'),\n",
       " np.str_('bride'),\n",
       " np.str_('spear'),\n",
       " np.str_('oedipus'),\n",
       " np.str_('heracles'),\n",
       " np.str_('cruel'),\n",
       " np.str_('helen'),\n",
       " np.str_('get'),\n",
       " np.str_('took'),\n",
       " np.str_('strangers'),\n",
       " np.str_('orestes'),\n",
       " np.str_('matter'),\n",
       " np.str_('curse'),\n",
       " np.str_('hades'),\n",
       " np.str_('gates'),\n",
       " np.str_('enemy'),\n",
       " np.str_('state'),\n",
       " np.str_('sake'),\n",
       " np.str_('lay'),\n",
       " np.str_('fallen'),\n",
       " np.str_('desire'),\n",
       " np.str_('dark'),\n",
       " np.str_('clearly'),\n",
       " np.str_('citizens'),\n",
       " np.str_('together'),\n",
       " np.str_('pass'),\n",
       " np.str_('exile'),\n",
       " np.str_('agamemnon'),\n",
       " np.str_('truly'),\n",
       " np.str_('pray'),\n",
       " np.str_('doth'),\n",
       " np.str_('creon'),\n",
       " np.str_('told'),\n",
       " np.str_('strange'),\n",
       " np.str_('silence'),\n",
       " np.str_('next'),\n",
       " np.str_('menelaus'),\n",
       " np.str_('high'),\n",
       " np.str_('dwell'),\n",
       " np.str_('doom'),\n",
       " np.str_('doing'),\n",
       " np.str_('tongue'),\n",
       " np.str_('story'),\n",
       " np.str_('none'),\n",
       " np.str_('nature'),\n",
       " np.str_('maiden'),\n",
       " np.str_('grant'),\n",
       " np.str_('golden'),\n",
       " np.str_('corpse'),\n",
       " np.str_('answer'),\n",
       " np.str_('witness'),\n",
       " np.str_('ready'),\n",
       " np.str_('palace'),\n",
       " np.str_('less'),\n",
       " np.str_('divine'),\n",
       " np.str_('days'),\n",
       " np.str_('clear'),\n",
       " np.str_('bed'),\n",
       " np.str_('until'),\n",
       " np.str_('sacred'),\n",
       " np.str_('foot'),\n",
       " np.str_('destroyed'),\n",
       " np.str_('bore'),\n",
       " np.str_('thoughts'),\n",
       " np.str_('sufferings'),\n",
       " np.str_('rather'),\n",
       " np.str_('past'),\n",
       " np.str_('hapless'),\n",
       " np.str_('eye'),\n",
       " np.str_('victory'),\n",
       " np.str_('terrible'),\n",
       " np.str_('sleep'),\n",
       " np.str_('shrine'),\n",
       " np.str_('perhaps'),\n",
       " np.str_('neither'),\n",
       " np.str_('instead'),\n",
       " np.str_('close'),\n",
       " np.str_('above'),\n",
       " np.str_('wealth'),\n",
       " np.str_('robe'),\n",
       " np.str_('gold'),\n",
       " np.str_('gain'),\n",
       " np.str_('farewell'),\n",
       " np.str_('wild'),\n",
       " np.str_('vain'),\n",
       " np.str_('towards'),\n",
       " np.str_('sire'),\n",
       " np.str_('saying'),\n",
       " np.str_('round'),\n",
       " np.str_('oath'),\n",
       " np.str_('hate'),\n",
       " np.str_('bloody'),\n",
       " np.str_('blame'),\n",
       " np.str_('thyself'),\n",
       " np.str_('three'),\n",
       " np.str_('seek'),\n",
       " np.str_('oracle'),\n",
       " np.str_('kind'),\n",
       " np.str_('become'),\n",
       " np.str_('wisdom'),\n",
       " np.str_('walls'),\n",
       " np.str_('utter'),\n",
       " np.str_('suppliant'),\n",
       " np.str_('rule'),\n",
       " np.str_('miserable'),\n",
       " np.str_('enemies'),\n",
       " np.str_('carry'),\n",
       " np.str_('aid'),\n",
       " np.str_('wretch'),\n",
       " np.str_('world'),\n",
       " np.str_('work'),\n",
       " np.str_('temple'),\n",
       " np.str_('sun'),\n",
       " np.str_('seeing'),\n",
       " np.str_('mighty'),\n",
       " np.str_('bound'),\n",
       " np.str_('youth'),\n",
       " np.str_('whoever'),\n",
       " np.str_('toil'),\n",
       " np.str_('someone'),\n",
       " np.str_('safe'),\n",
       " np.str_('misfortune'),\n",
       " np.str_('listen'),\n",
       " np.str_('hither'),\n",
       " np.str_('held'),\n",
       " np.str_('charge'),\n",
       " np.str_('caught'),\n",
       " np.str_('bow'),\n",
       " np.str_('went'),\n",
       " np.str_('war'),\n",
       " np.str_('spirit'),\n",
       " np.str_('shield'),\n",
       " np.str_('queen'),\n",
       " np.str_('offspring'),\n",
       " np.str_('knees'),\n",
       " np.str_('happened'),\n",
       " np.str_('boy'),\n",
       " np.str_('ajax'),\n",
       " np.str_('age'),\n",
       " np.str_('praise'),\n",
       " np.str_('piteous'),\n",
       " np.str_('path'),\n",
       " np.str_('hail'),\n",
       " np.str_('flight'),\n",
       " np.str_('deep'),\n",
       " np.str_('around'),\n",
       " np.str_('act'),\n",
       " np.str_('wrong'),\n",
       " np.str_('therefore'),\n",
       " np.str_('receive'),\n",
       " np.str_('reach'),\n",
       " np.str_('making'),\n",
       " np.str_('inside'),\n",
       " np.str_('further'),\n",
       " np.str_('evils'),\n",
       " np.str_('anger'),\n",
       " np.str_('strength'),\n",
       " np.str_('stay'),\n",
       " np.str_('silent'),\n",
       " np.str_('saved'),\n",
       " np.str_('safety'),\n",
       " np.str_('rock'),\n",
       " np.str_('rites'),\n",
       " np.str_('pay'),\n",
       " np.str_('leaving'),\n",
       " np.str_('going'),\n",
       " np.str_('god’s'),\n",
       " np.str_('given'),\n",
       " np.str_('family'),\n",
       " np.str_('eager'),\n",
       " np.str_('darkness'),\n",
       " np.str_('artemis'),\n",
       " np.str_('wrath'),\n",
       " np.str_('taking'),\n",
       " np.str_('taken'),\n",
       " np.str_('sweet'),\n",
       " np.str_('service'),\n",
       " np.str_('purpose'),\n",
       " np.str_('meet'),\n",
       " np.str_('madness'),\n",
       " np.str_('honour'),\n",
       " np.str_('fell'),\n",
       " np.str_('endure'),\n",
       " np.str_('died'),\n",
       " np.str_('daughters'),\n",
       " np.str_('blessed'),\n",
       " np.str_('yea'),\n",
       " np.str_('welcome'),\n",
       " np.str_('turned'),\n",
       " np.str_('suffered'),\n",
       " np.str_('ruined'),\n",
       " np.str_('plain'),\n",
       " np.str_('loxias'),\n",
       " np.str_('knowledge'),\n",
       " np.str_('former'),\n",
       " np.str_('cut'),\n",
       " np.str_('although'),\n",
       " np.str_('along'),\n",
       " np.str_('afraid'),\n",
       " np.str_('wicked'),\n",
       " np.str_('touch'),\n",
       " np.str_('terror'),\n",
       " np.str_('shalt'),\n",
       " np.str_('servants'),\n",
       " np.str_('sail'),\n",
       " np.str_('obey'),\n",
       " np.str_('lest'),\n",
       " np.str_('knows'),\n",
       " np.str_('judgment'),\n",
       " np.str_('guard'),\n",
       " np.str_('form'),\n",
       " np.str_('foreign'),\n",
       " np.str_('equal'),\n",
       " np.str_('counsel'),\n",
       " np.str_('bury'),\n",
       " np.str_('ares'),\n",
       " np.str_('apollo'),\n",
       " np.str_('account'),\n",
       " np.str_('watch'),\n",
       " np.str_('theseus'),\n",
       " np.str_('streams'),\n",
       " np.str_('secret'),\n",
       " np.str_('savage'),\n",
       " np.str_('received'),\n",
       " np.str_('ought'),\n",
       " np.str_('mad'),\n",
       " np.str_('lips'),\n",
       " np.str_('kept'),\n",
       " np.str_('haste'),\n",
       " np.str_('glorious'),\n",
       " np.str_('girl'),\n",
       " np.str_('dreadful'),\n",
       " np.str_('dearest'),\n",
       " np.str_('deadly'),\n",
       " np.str_('children’s'),\n",
       " np.str_('beside'),\n",
       " np.str_('anything'),\n",
       " np.str_('understand'),\n",
       " np.str_('town'),\n",
       " np.str_('tidings'),\n",
       " np.str_('spoken'),\n",
       " np.str_('something'),\n",
       " np.str_('peace'),\n",
       " np.str_('mourn'),\n",
       " np.str_('ill'),\n",
       " np.str_('feet'),\n",
       " np.str_('everything'),\n",
       " np.str_('chariot'),\n",
       " np.str_('below'),\n",
       " np.str_('unless'),\n",
       " np.str_('strife'),\n",
       " np.str_('point'),\n",
       " np.str_('native'),\n",
       " np.str_('makes'),\n",
       " np.str_('law'),\n",
       " np.str_('lament'),\n",
       " np.str_('host'),\n",
       " np.str_('gift'),\n",
       " np.str_('ere'),\n",
       " np.str_('destroy'),\n",
       " np.str_('cease'),\n",
       " np.str_('breast'),\n",
       " np.str_('argives'),\n",
       " np.str_('task'),\n",
       " np.str_('slaughter'),\n",
       " np.str_('sad'),\n",
       " np.str_('prayers'),\n",
       " np.str_('order'),\n",
       " np.str_('lies'),\n",
       " np.str_('lie'),\n",
       " np.str_('keeping'),\n",
       " np.str_('human'),\n",
       " np.str_('grievous'),\n",
       " np.str_('foe'),\n",
       " np.str_('flesh'),\n",
       " np.str_('feel'),\n",
       " np.str_('crown'),\n",
       " np.str_('common'),\n",
       " np.str_('white'),\n",
       " np.str_('wait'),\n",
       " np.str_('vengeance'),\n",
       " np.str_('stands'),\n",
       " np.str_('song'),\n",
       " np.str_('question'),\n",
       " np.str_('pallas'),\n",
       " np.str_('offer'),\n",
       " np.str_('maidens'),\n",
       " np.str_('living'),\n",
       " np.str_('little'),\n",
       " np.str_('grave'),\n",
       " np.str_('foes'),\n",
       " np.str_('declare'),\n",
       " np.str_('burial'),\n",
       " np.str_('birds'),\n",
       " np.str_('anyone'),\n",
       " np.str_('anguish'),\n",
       " np.str_('ancient'),\n",
       " np.str_('air'),\n",
       " np.str_('achilles'),\n",
       " np.str_('unto'),\n",
       " np.str_('towers'),\n",
       " np.str_('throne'),\n",
       " np.str_('struck'),\n",
       " np.str_('single'),\n",
       " np.str_('report'),\n",
       " np.str_('raise'),\n",
       " np.str_('pure'),\n",
       " np.str_('prove'),\n",
       " np.str_('odysseus'),\n",
       " np.str_('lives'),\n",
       " np.str_('hide'),\n",
       " np.str_('fly'),\n",
       " np.str_('escaped'),\n",
       " np.str_('due'),\n",
       " np.str_('cries'),\n",
       " np.str_('certain'),\n",
       " np.str_('carried'),\n",
       " np.str_('barbarian'),\n",
       " np.str_('atreus'),\n",
       " np.str_('wings'),\n",
       " np.str_('use'),\n",
       " np.str_('swift'),\n",
       " np.str_('seat'),\n",
       " np.str_('regard'),\n",
       " np.str_('laws'),\n",
       " np.str_('laid'),\n",
       " np.str_('harm'),\n",
       " np.str_('dread'),\n",
       " np.str_('brings'),\n",
       " np.str_('bright'),\n",
       " np.str_('altars'),\n",
       " np.str_('alike'),\n",
       " np.str_('steps'),\n",
       " np.str_('seize'),\n",
       " np.str_('remain'),\n",
       " np.str_('oracles'),\n",
       " np.str_('naught'),\n",
       " np.str_('maid'),\n",
       " np.str_('loud'),\n",
       " np.str_('hera'),\n",
       " np.str_('fierce'),\n",
       " np.str_('double'),\n",
       " np.str_('delay'),\n",
       " np.str_('command'),\n",
       " np.str_('childless'),\n",
       " np.str_('cadmus'),\n",
       " np.str_('believe'),\n",
       " np.str_('allow'),\n",
       " np.str_('wind'),\n",
       " np.str_('wherefore'),\n",
       " np.str_('water'),\n",
       " np.str_('tear'),\n",
       " np.str_('sit'),\n",
       " np.str_('ships'),\n",
       " np.str_('shameful'),\n",
       " np.str_('really'),\n",
       " np.str_('pleasure'),\n",
       " np.str_('penalty'),\n",
       " np.str_('nay'),\n",
       " np.str_('lo'),\n",
       " np.str_('holds'),\n",
       " np.str_('heavy'),\n",
       " np.str_('greater'),\n",
       " np.str_('fresh'),\n",
       " np.str_('favor'),\n",
       " np.str_('driven'),\n",
       " np.str_('dance'),\n",
       " np.str_('apart'),\n",
       " np.str_('yield'),\n",
       " np.str_('worthy'),\n",
       " np.str_('winged'),\n",
       " np.str_('weep'),\n",
       " np.str_('waves'),\n",
       " np.str_('unfortunate'),\n",
       " np.str_('stood'),\n",
       " np.str_('slew'),\n",
       " np.str_('reverence'),\n",
       " np.str_('reproach'),\n",
       " np.str_('prophet'),\n",
       " np.str_('plague'),\n",
       " np.str_('perish'),\n",
       " np.str_('moment'),\n",
       " np.str_('led'),\n",
       " np.str_('laius'),\n",
       " np.str_('knew'),\n",
       " np.str_('horses'),\n",
       " np.str_('herald'),\n",
       " np.str_('hateful'),\n",
       " np.str_('glory'),\n",
       " np.str_('fury'),\n",
       " np.str_('follow'),\n",
       " np.str_('embrace'),\n",
       " np.str_('distress'),\n",
       " np.str_('brave'),\n",
       " np.str_('aught'),\n",
       " np.str_('achaeans'),\n",
       " np.str_('won'),\n",
       " np.str_('wert'),\n",
       " np.str_('ways'),\n",
       " np.str_('violence'),\n",
       " np.str_('throw'),\n",
       " np.str_('stop'),\n",
       " np.str_('sky'),\n",
       " np.str_('serve'),\n",
       " np.str_('seem'),\n",
       " np.str_('royal'),\n",
       " np.str_('pollution'),\n",
       " np.str_('passed'),\n",
       " np.str_('open'),\n",
       " np.str_('mischief'),\n",
       " np.str_('message'),\n",
       " np.str_('guide'),\n",
       " np.str_('gives'),\n",
       " np.str_('fearful'),\n",
       " np.str_('endured'),\n",
       " np.str_('doubt'),\n",
       " np.str_('curses'),\n",
       " np.str_('ago'),\n",
       " np.str_('woman’s'),\n",
       " np.str_('utterly'),\n",
       " np.str_('shed'),\n",
       " np.str_('seven'),\n",
       " np.str_('prayer'),\n",
       " np.str_('plan'),\n",
       " np.str_('persuade'),\n",
       " np.str_('ones'),\n",
       " np.str_('murderous'),\n",
       " np.str_('hated'),\n",
       " np.str_('dying'),\n",
       " np.str_('destruction'),\n",
       " np.str_('destiny'),\n",
       " np.str_('delight'),\n",
       " np.str_('countless'),\n",
       " np.str_('consider'),\n",
       " np.str_('certainly'),\n",
       " np.str_('bad'),\n",
       " np.str_('wouldst'),\n",
       " np.str_('woes'),\n",
       " np.str_('whatever'),\n",
       " np.str_('view'),\n",
       " np.str_('sound'),\n",
       " np.str_('sense'),\n",
       " np.str_('seer'),\n",
       " np.str_('seeking'),\n",
       " np.str_('persuaded'),\n",
       " np.str_('pentheus'),\n",
       " np.str_('parents'),\n",
       " np.str_('mankind'),\n",
       " np.str_('loose'),\n",
       " np.str_('homes'),\n",
       " np.str_('heaven’s'),\n",
       " np.str_('harsh'),\n",
       " np.str_('grieve'),\n",
       " np.str_('gifts'),\n",
       " np.str_('future'),\n",
       " np.str_('food'),\n",
       " np.str_('flame'),\n",
       " np.str_('fame'),\n",
       " np.str_('false'),\n",
       " np.str_('duty'),\n",
       " np.str_('draw'),\n",
       " np.str_('chamber'),\n",
       " np.str_('burden'),\n",
       " np.str_('wonder'),\n",
       " np.str_('whenever'),\n",
       " np.str_('wailing'),\n",
       " np.str_('tyndareus'),\n",
       " np.str_('try'),\n",
       " np.str_('struggle'),\n",
       " np.str_('speaking'),\n",
       " np.str_('rocks'),\n",
       " np.str_('rich'),\n",
       " np.str_('remember'),\n",
       " np.str_('refuse'),\n",
       " np.str_('quickly'),\n",
       " np.str_('punishment'),\n",
       " np.str_('prosperity'),\n",
       " np.str_('polyneices'),\n",
       " np.str_('please'),\n",
       " np.str_('outside'),\n",
       " np.str_('mourning'),\n",
       " np.str_('men’s'),\n",
       " np.str_('menelaos'),\n",
       " np.str_('matters'),\n",
       " np.str_('loved'),\n",
       " np.str_('judge'),\n",
       " np.str_('join'),\n",
       " np.str_('hopes'),\n",
       " np.str_('herself'),\n",
       " np.str_('goes'),\n",
       " np.str_('drive'),\n",
       " np.str_('dionysus'),\n",
       " np.str_('different'),\n",
       " np.str_('courage'),\n",
       " np.str_('change'),\n",
       " np.str_('catch'),\n",
       " np.str_('captive'),\n",
       " np.str_('breath'),\n",
       " np.str_('arm'),\n",
       " np.str_('argos'),\n",
       " np.str_('unholy'),\n",
       " np.str_('toils'),\n",
       " np.str_('suppose'),\n",
       " np.str_('small'),\n",
       " np.str_('says'),\n",
       " np.str_('robes'),\n",
       " np.str_('release'),\n",
       " np.str_('often'),\n",
       " np.str_('learned'),\n",
       " np.str_('issue'),\n",
       " np.str_('impious'),\n",
       " np.str_('household'),\n",
       " np.str_('grow'),\n",
       " np.str_('goddesses'),\n",
       " np.str_('gate'),\n",
       " np.str_('feast'),\n",
       " np.str_('fain'),\n",
       " np.str_('e’en'),\n",
       " np.str_('except'),\n",
       " np.str_('decide'),\n",
       " np.str_('cure'),\n",
       " np.str_('count'),\n",
       " np.str_('chance'),\n",
       " np.str_('bold'),\n",
       " np.str_('black'),\n",
       " np.str_('bid'),\n",
       " np.str_('begin'),\n",
       " np.str_('babe'),\n",
       " np.str_('approach'),\n",
       " np.str_('undone'),\n",
       " np.str_('strong'),\n",
       " np.str_('storm'),\n",
       " np.str_('spoke'),\n",
       " np.str_('shore'),\n",
       " np.str_('rage'),\n",
       " np.str_('prize'),\n",
       " np.str_('one’s'),\n",
       " np.str_('neck'),\n",
       " np.str_('mere'),\n",
       " np.str_('hellenes'),\n",
       " np.str_('gods’'),\n",
       " np.str_('frenzy'),\n",
       " np.str_('folly'),\n",
       " np.str_('filled'),\n",
       " np.str_('easy'),\n",
       " np.str_('clever'),\n",
       " np.str_('between'),\n",
       " np.str_('beasts'),\n",
       " np.str_('bacchae'),\n",
       " np.str_('appear'),\n",
       " np.str_('angry'),\n",
       " np.str_('add'),\n",
       " np.str_('action'),\n",
       " np.str_('years'),\n",
       " np.str_('willing'),\n",
       " np.str_('victims'),\n",
       " np.str_('thinking'),\n",
       " np.str_('stream'),\n",
       " np.str_('stars'),\n",
       " np.str_('slaying'),\n",
       " np.str_('sides'),\n",
       " np.str_('shouldst'),\n",
       " np.str_('quick'),\n",
       " np.str_('proud'),\n",
       " np.str_('powers'),\n",
       " np.str_('offering'),\n",
       " np.str_('necessity'),\n",
       " np.str_('lamentation'),\n",
       " np.str_('hellas'),\n",
       " np.str_('hearth'),\n",
       " np.str_('happiness'),\n",
       " np.str_('giving'),\n",
       " np.str_('foolish'),\n",
       " np.str_('dust'),\n",
       " np.str_('dire'),\n",
       " np.str_('crime'),\n",
       " np.str_('company'),\n",
       " np.str_('behind'),\n",
       " np.str_('advice'),\n",
       " np.str_('yoke'),\n",
       " np.str_('wound'),\n",
       " np.str_('worse'),\n",
       " np.str_('weeping'),\n",
       " np.str_('victim'),\n",
       " np.str_('till'),\n",
       " np.str_('tent'),\n",
       " np.str_('tender'),\n",
       " np.str_('success'),\n",
       " np.str_('stone'),\n",
       " np.str_('source'),\n",
       " np.str_('reveal'),\n",
       " np.str_('respect'),\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
